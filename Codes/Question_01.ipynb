{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DeferredError' has no attribute 'new'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\pasin\\anaconda3\\envs\\hmp1\\lib\\site-packages\\PIL\\Image.py:105\u001b[0m\n\u001b[0;32m    100\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m         )\n\u001b[1;32m--> 105\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m v:\n",
      "\u001b[1;31mImportError\u001b[0m: The _imaging extension was built for another version of Pillow or PIL:\nCore version: 11.0.0\nPillow version: 9.3.0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pasin\\anaconda3\\envs\\hmp1\\lib\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pasin\\anaconda3\\envs\\hmp1\\lib\\site-packages\\torchvision\\datasets\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optical_flow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stereo_matching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     CarlaStereo,\n\u001b[0;32m      4\u001b[0m     CREStereo,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     SintelStereo,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcaltech\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Caltech101, Caltech256\n",
      "File \u001b[1;32mc:\\Users\\pasin\\anaconda3\\envs\\hmp1\\lib\\site-packages\\torchvision\\datasets\\_optical_flow.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decode_png, read_file\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _read_pfm, verify_str_arg\n",
      "File \u001b[1;32mc:\\Users\\pasin\\anaconda3\\envs\\hmp1\\lib\\site-packages\\PIL\\Image.py:108\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m v:\n\u001b[1;32m--> 108\u001b[0m     core \u001b[38;5;241m=\u001b[39m \u001b[43mDeferredError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m(\u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging C module is not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Explanations for ways that we know we might have an import error\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(v)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule use of python\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;66;03m# The _imaging C module is present, but not compiled for\u001b[39;00m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;66;03m# the right version (windows only).  Print a warning, if\u001b[39;00m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;66;03m# possible.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'DeferredError' has no attribute 'new'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Dataloading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 50\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 2. Define Network Parameters\n",
    "Din = 3 * 32 * 32  # Input size (flattened CIFAR-10 image size)\n",
    "H = 100  # Hidden layer size\n",
    "K = 10  # Output size (number of classes in CIFAR-10)\n",
    "std = 1e-5\n",
    "\n",
    "# Initialize weights and biases\n",
    "w1 = torch.randn(Din, H) * std  # Input to hidden layer\n",
    "b1 = torch.zeros(H)\n",
    "w2 = torch.randn(H, K) * std  # Hidden to output layer\n",
    "b2 = torch.zeros(K)\n",
    "\n",
    "# Hyperparameters\n",
    "iterations = 10\n",
    "lr = 2e-6  # Learning rate\n",
    "lr_decay = 0.9  # Learning rate decay\n",
    "reg = 0  # Regularization\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "# Define Cross-Entropy Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 3. Training Loop\n",
    "for epoch in range(iterations):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        Ntr = inputs.shape[0]  # Batch size\n",
    "        x_train = inputs.view(Ntr, -1)  # Flatten input to (Ntr, Din)\n",
    "        \n",
    "        # Forward pass\n",
    "        h = torch.sigmoid(x_train.mm(w1) + b1)  # Sigmoid activation for the hidden layer\n",
    "        y_pred = h.mm(w2) + b2  # Output layer activation\n",
    "\n",
    "        # Loss calculation (Cross-Entropy Loss with regularization)\n",
    "        loss = criterion(y_pred, labels) + reg * (torch.sum(w1 ** 2) + torch.sum(w2 ** 2))\n",
    "        loss_history.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Backpropagation (Manual)\n",
    "        dy_pred = torch.softmax(y_pred, dim=1) - nn.functional.one_hot(labels, K).float()  # Gradient for cross-entropy\n",
    "        dw2 = h.t().mm(dy_pred) + reg * w2  # Gradient for w2\n",
    "        db2 = dy_pred.sum(dim=0)  # Gradient for b2\n",
    "\n",
    "        dh = dy_pred.mm(w2.t()) * h * (1 - h)  # Gradient through sigmoid activation\n",
    "        dw1 = x_train.t().mm(dh) + reg * w1  # Gradient for w1\n",
    "        db1 = dh.sum(dim=0)  # Gradient for b1\n",
    "\n",
    "        # Update weights and biases\n",
    "        w1 -= lr * dw1\n",
    "        b1 -= lr * db1\n",
    "        w2 -= lr * dw2\n",
    "        b2 -= lr * db2\n",
    "\n",
    "    # Print loss for every epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{iterations}], Loss: {running_loss / len(trainloader):.4f}\")\n",
    "\n",
    "\n",
    "    # Learning rate decay\n",
    "    lr *= lr_decay\n",
    "\n",
    "# 4. Plotting the Loss History\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Loss History\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()  \n",
    "\n",
    "# 5. Evaluate on Training Set\n",
    "with torch.no_grad():\n",
    "    # Training accuracy\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        Ntr = inputs.shape[0]\n",
    "        x_train = inputs.view(Ntr, -1)\n",
    "        y_train_onehot = nn.functional.one_hot(labels, K).float()\n",
    "        h = torch.sigmoid(x_train.mm(w1) + b1)\n",
    "        y_train_pred = h.mm(w2) + b2\n",
    "        predicted_train = torch.argmax(y_train_pred, dim=1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    print(f\"Training accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# 6. Evaluate on Test Set\n",
    "with torch.no_grad():\n",
    "    # Test accuracy\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        Nte = inputs.shape[0]\n",
    "        x_test = inputs.view(Nte, -1)\n",
    "        y_test_onehot = nn.functional.one_hot(labels, K).float()\n",
    "        h = torch.sigmoid(x_test.mm(w1) + b1)\n",
    "        y_test_pred = h.mm(w2) + b2\n",
    "        predicted_test = torch.argmax(y_test_pred, dim=1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted_test == labels).sum().item()\n",
    "    test_acc = 100 * correct_test / total_test\n",
    "    print(f\"Test accuracy: {test_acc:.2f}%\")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
